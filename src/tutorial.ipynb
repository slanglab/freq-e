{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq-E example usage \n",
    "Starting with a collection of text documents. This notebook walks through: \n",
    "\n",
    "1. Getting text in a format suitable for input into freq-e\n",
    "\n",
    "2. How to run freq-e to obtain prevalence estimates on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np \n",
    "import json\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import estimate\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing \n",
    "We will use the Yelp academic dataset as an example. The text representation will be unigram counts (e.g. \"bag-of-words\"). Here, we have already calcuated the BOW counts and saved them as a .json file. The y-values are negative sentiment (y=0) and positive sentiment (y=1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_x_y_from_json(file_name): \n",
    "    count_dicts = []\n",
    "    y = []\n",
    "    for line in open(file_name): \n",
    "        dd = json.loads(line)\n",
    "        counts = dd['counts'].copy()\n",
    "        cc = dd['class']\n",
    "        count_dicts.append(counts); y.append(cc)\n",
    "    return count_dicts, np.array(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_vocab(X_train, dv_vocab): \n",
    "    #remove words that occur in <5 docs \n",
    "    xx=X_train.copy()\n",
    "    xx[xx>0]=1\n",
    "    w_df = np.asarray(xx.sum(0)).flatten()\n",
    "    new_vocab_mask = w_df >= 5\n",
    "    print(\"Orig vocab %d, pruned %d\" % (len(w_df), np.sum(new_vocab_mask)))\n",
    "    X_train = X_train[:,new_vocab_mask]\n",
    "    dv_vocab = dv_vocab[new_vocab_mask]\n",
    "    return X_train, dv_vocab, new_vocab_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig vocab 14791, pruned 3112\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(2000, 3112) (2000,)\n"
     ]
    }
   ],
   "source": [
    "#get train data \n",
    "dv = DictVectorizer()\n",
    "train_count_dicts, y_train = load_x_y_from_json('example_data/train_yelp.json')\n",
    "X_train = dv.fit_transform(train_count_dicts).toarray()\n",
    "dv_vocab = np.array(dv.feature_names_)\n",
    "X_train, dv_vocab, new_vocab_mask = prune_vocab(X_train, dv_vocab)\n",
    "print(type(X_train), type(y_train))\n",
    "print(X_train.shape, y_train.shape)\n",
    "assert X_train.shape[0] == y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(test_count_dicts, new_vocab_mask): \n",
    "    X_test = dv.transform(test_count_dicts).toarray()\n",
    "    X_test = X_test[:,new_vocab_mask]\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(2000, 3112) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# get test data (1 test group) \n",
    "# NOTE: the test group is the \"inference\" group in a real-word setting\n",
    "# here we have labels on the test set, but in a real-word setting there \n",
    "# would most likely not be labels on the test set\n",
    "test_count_dicts, y_test = load_x_y_from_json('example_data/test_yelp.json')\n",
    "X_test = transform_test(test_count_dicts, new_vocab_mask)\n",
    "print(type(X_test), type(y_test))\n",
    "print(X_test.shape, y_test.shape)\n",
    "assert X_test.shape[1] == X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq-e usage\n",
    "\n",
    "## Inference\n",
    "Freq-e inference will return (1) a point estimate of the class frequency/proportions and (2) a confidence interval for the point estimate. \n",
    "\n",
    "There are two distict methods one can get a frequency estimate: \n",
    "1. Pass in a trainined scikit-learn linear model (such as logistic regtression)\n",
    "2. Pass in the predicted probabilities of the positive class of the test set. \n",
    "\n",
    "You might want to use Method 2 in the case where you have some specialzed classifier that is not a part of sklearn.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 (pass in instance of sklearn.linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "- In order to select the best discriminitive classifier, we will do a grid search over the L1 penalties for LogReg, evaluating on cross-entropy over 10 cross-validation folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DISCRIMINATIVE MODEL\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=None, solver='liblinear',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Training mean accuracy= 0.9635\n"
     ]
    }
   ],
   "source": [
    "freq_e = estimate.FreqEstimate()\n",
    "trained_model = freq_e.fit_disc_classifier(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large test group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "0.769\n"
     ]
    }
   ],
   "source": [
    "# here we can know the true proportions because we have access to the test labels \n",
    "print('TRUE')\n",
    "print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC\n",
      "0.7694202722821978\n"
     ]
    }
   ],
   "source": [
    "#naive method = PCC (probabilistic classify and count)\n",
    "print('PCC')\n",
    "print(np.mean(trained_model.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.772, 'conf_interval': (0.748, 0.795)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "out = freq_e.infer_freq(y_train, X_test, conf_level=0.95, trained_model=trained_model, test_pred_probs=None)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High prevalence test group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 3112) (415,)\n"
     ]
    }
   ],
   "source": [
    "test_count_dicts2, y_test2 = load_x_y_from_json('testgroup_zpoZ6WyQUYff18-z4ZU1mA/zpoZ6WyQUYff18-z4ZU1mA')\n",
    "X_test2 = transform_test(test_count_dicts2, new_vocab_mask)\n",
    "print(X_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "0.9686746987951808\n"
     ]
    }
   ],
   "source": [
    "print('TRUE')\n",
    "print(np.mean(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC\n",
      "0.9019348999589916\n"
     ]
    }
   ],
   "source": [
    "print('PCC')\n",
    "print(np.mean(trained_model.predict_proba(X_test2)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.973, 'conf_interval': (0.9440000000000001, 0.992)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "out = freq_e.infer_freq(y_train, X_test2, conf_level=0.95, trained_model=trained_model, test_pred_probs=None)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low prevalence test group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 3112) (825,)\n"
     ]
    }
   ],
   "source": [
    "test_count_dicts3, y_test3 = load_x_y_from_json('dWFUKB_HPBIE87AFBHEb_w')\n",
    "X_test3 = transform_test(test_count_dicts3, new_vocab_mask)\n",
    "print(X_test3.shape, y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "0.13696969696969696\n"
     ]
    }
   ],
   "source": [
    "print('TRUE')\n",
    "print(np.mean(y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC\n",
      "0.31147433158714605\n"
     ]
    }
   ],
   "source": [
    "print('PCC')\n",
    "print(np.mean(trained_model.predict_proba(X_test3)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.046, 'conf_interval': (0.028, 0.069)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "out = freq_e.infer_freq(y_train, X_test3, conf_level=0.95, trained_model=trained_model, test_pred_probs=None)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 (pass in predicted probabilites on the test set)\n",
    "We will show this results in the same frequency estimate as the last group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.92084161e-08 8.55934549e-01 8.43841482e-01 6.97602815e-02\n",
      " 1.48921023e-01]\n"
     ]
    }
   ],
   "source": [
    "# get the probabilities for the positive class \n",
    "test_pred_probs = trained_model.predict_proba(X_test3)[:, 1]\n",
    "print(test_pred_probs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.046, 'conf_interval': (0.028, 0.069)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "out = freq_e.infer_freq(y_train, X_test3, conf_level=0.95, trained_model=None, test_pred_probs=test_pred_probs)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
