{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# freq-e tutorial \n",
    "This notebook walks through: \n",
    "How to run freq-e to obtain prevalence estimates on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dependencies \n",
    "import numpy as np \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load freq_e package and tutorial data-preprocessing utils \n",
    "from freq_e import estimate\n",
    "import tutorial_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing \n",
    "freq-e must have data in the following format \n",
    "- `X_train` : numpy.ndarray, shape=(number of training examples, number of features) \n",
    "- `y_train` : numpy.ndarray (binary 0's and 1's), shape=(number of training examples,) \n",
    "- `X_test` : numpy.ndarray, shape=(number of test/inference examples, number of *training* features)\n",
    "\n",
    "Often you will have *multiple* test groups. In this case you should have an `X_test` for each test group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Yelp academic dataset as an example. The text representation will be unigram counts (e.g. \"bag-of-words\"). Here, we have already calcuated the BOW counts and saved them as a .json file. The y-values are negative sentiment (y=0) and positive sentiment (y=1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig vocab 14791, pruned 3112\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(2000, 3112) (2000,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(2000, 3112) (2000,)\n"
     ]
    }
   ],
   "source": [
    "#load pre-processed data \n",
    "X_train, y_train, dict_vect, vocab_mask = tutorial_utils.get_train_data('../example_data/train_yelp.json')\n",
    "X_test, y_test = tutorial_utils.get_test_group('../example_data/test_yelp.json', vocab_mask, dict_vect)\n",
    "assert X_test.shape[1] == X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq-e usage\n",
    "\n",
    "## Inference\n",
    "Freq-e inference will return (1) a point estimate of the class frequency/proportions and (2) a confidence interval for the point estimate. \n",
    "\n",
    "There are three different ways to obtain estimates: \n",
    "1. Create a `FreqEstimate` object and use the built-in training method. \n",
    "2. Use the `infer_freq()` method and pass in a pre-trained scikit-learn linear model (e.g. Logistic_Regression). Here the model class is restricted to scikit-learn models that have a .decision_function() method. \n",
    "3. Use the `infer_freq()` method and pass in the predicted probabilities of the positive class of the test set. \n",
    "\n",
    "Method 3 may be useful in the cases where you have special classifier architectures that are not built from sklearn (e.g. an LSTM or CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 (train internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a freq-e object \n",
    "FreqE = estimate.FreqEstimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "The FreqEstimate model object can train a discriminative logistic regression classifier for you. It uses grid search over the L1 penalties, evaluating on cross-entropy over 10 cross-validation folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING LOGISTIC REGRESSION MODEL\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Training mean accuracy= 0.9635\n"
     ]
    }
   ],
   "source": [
    "FreqE.train_cross_val(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference \n",
    "We will get a prevalence point estimate and a 95% confidence interval. One can change the confidence level as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.77200000000000002, 'conf_interval_95%': (0.748, 0.79500000000000004)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "out = FreqE.infer_freq_obj(X_test, conf_level=0.95)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.77200000000000002, 'conf_interval_80%': (0.75600000000000001, 0.78700000000000003)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "out = FreqE.infer_freq_obj(X_test, conf_level=0.8)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare this to other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "0.769\n"
     ]
    }
   ],
   "source": [
    "# In our example, we know the true class proportion because we have access to the test labels\n",
    "# This is not the case if you are doing true inference \n",
    "print('TRUE')\n",
    "print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC\n",
      "0.769420484056\n"
     ]
    }
   ],
   "source": [
    "#naive method = PCC (probabilistic classify and count)\n",
    "print('PCC')\n",
    "trained_model = FreqE.trained_model #used the logistic regression model we already trained \n",
    "probs = trained_model.predict_proba(X_test)[:, 1] #get the soft probabilites \n",
    "print(np.mean(probs)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 (pre-trained scikit-learn linear model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also train a scikit-learn classifier yourself and pass it in to freq-e.  This may be useful if you want to use different hyperparameters or different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "trained_model = LinearSVC()\n",
    "trained_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.57400000000000007, 'conf_interval': (0.53800000000000003, 0.60899999999999999), 'conf_level': 0.95}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "label_prior = np.mean(y_train) #most often, you want to estimate the label prior from training, but you can also pass in other values\n",
    "out = estimate.infer_freq(X_test, label_prior, conf_level=0.95, trained_model=trained_model)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do a lot worse since we obviously haven't tuned the hyperparameters for the SVC (and we wouldn't recommend SVC over logistic regression for this ask). However, if you're using a classifier that has been fine-tuned on the training data (e.g. a LSTM or Transformer with logistic output) this method should work well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 (pass in predicted probabilites on the test set)\n",
    "\n",
    "Finally, you can do both the classifier training and prediction yourself.  All you need to do is get the predicted positive class probabilites on the test set (`test_pred_probs`) and pass them into the `infer_freq` stand-alone method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.75556119e-01   5.67236618e-05   9.99967121e-01   9.80429471e-01\n",
      "   7.78366752e-01]\n"
     ]
    }
   ],
   "source": [
    "# Let's train a LogisticRegression classifier (without hyperparameter tuning) \n",
    "# and get the probabilities for the positive class \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "trained_model2 = LogisticRegression()\n",
    "trained_model2.fit(X_train, y_train)\n",
    "test_pred_probs = trained_model2.predict_proba(X_test)[:, 1] #estimated probabilites for the positive class \n",
    "print(test_pred_probs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.78900000000000003, 'conf_interval': (0.76700000000000002, 0.81000000000000005), 'conf_level': 0.95}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "label_prior = np.mean(y_train)\n",
    "out = estimate.infer_freq(X_test, label_prior, conf_level=0.95, trained_model=None, test_pred_probs=test_pred_probs)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other test groups \n",
    "Here we examine two other test groups to show some anecdotes of why using our method is important when the training class prevalence does not match the true test class prevalence.  The empirical results in Keith et. al 2018 show this more rigorously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High prevalence test group  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test group has *higher* positive prevalence than the training data.  We expect PCC to give a too-low prediction, while freq-e should be closer to the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(415, 3112) (415,)\n",
      "(415, 3112) (415,)\n"
     ]
    }
   ],
   "source": [
    "X_test2, y_test2 = tutorial_utils.get_test_group('../example_data/high_prev.json', vocab_mask, dict_vect)\n",
    "print(X_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "0.968674698795\n"
     ]
    }
   ],
   "source": [
    "print('TRUE')\n",
    "print(np.mean(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.97299999999999998, 'conf_interval_95%': (0.94400000000000006, 0.99199999999999999)}\n"
     ]
    }
   ],
   "source": [
    "# Note: we don't have to re-train our frequency estimate object! we can just infer the \n",
    "# class proportions on this new test set \n",
    "print('FREQ-E ESTIMATED')\n",
    "out = FreqE.infer_freq_obj(X_test2, conf_level=0.95)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC\n",
      "0.901939977168\n"
     ]
    }
   ],
   "source": [
    "print('PCC')\n",
    "print(np.mean(FreqE.trained_model.predict_proba(X_test2)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low prevalence test group "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test group has *lower* prevalence than the training data.  We expect PCC to be biased upward, but freq-e to be closer to the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(825, 3112) (825,)\n",
      "(825, 3112) (825,)\n"
     ]
    }
   ],
   "source": [
    "X_test3, y_test3 = tutorial_utils.get_test_group('../example_data/low_prev.json', vocab_mask, dict_vect)\n",
    "print(X_test3.shape, y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "0.13696969697\n"
     ]
    }
   ],
   "source": [
    "print('TRUE')\n",
    "print(np.mean(y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.045999999999999999, 'conf_interval_95%': (0.028000000000000001, 0.069000000000000006)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "out = FreqE.infer_freq_obj(X_test3, conf_level=0.95)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC\n",
      "0.3114774782928134\n"
     ]
    }
   ],
   "source": [
    "print('PCC')\n",
    "print(np.mean(FreqE.trained_model.predict_proba(X_test3)[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
