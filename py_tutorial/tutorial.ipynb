{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# freq-e tutorial \n",
    "This notebook walks through: \n",
    "How to run freq-e to obtain prevalence estimates on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import freq_e\n",
    "import tutorial_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing \n",
    "freq-e must have data in the following format \n",
    "- `X_train` : numpy.ndarray, shape=(number of training examples, number of features) \n",
    "- `y_train` : numpy.ndarray (binary 0's and 1's), shape=(number of training examples,) \n",
    "- `X_test` : numpy.ndarray, shape=(number of test/inference examples, number of *training* features)\n",
    "\n",
    "Often you will have *multiple* test groups. In this case you should have an `X_test` for each test group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Yelp academic dataset as an example. The text representation will be unigram counts (e.g. \"bag-of-words\"). Here, we have already calcuated the BOW counts and saved them as a .json file. The y-values are negative sentiment (y=0) and positive sentiment (y=1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig vocab 14791, pruned 3112\n",
      "Training X shape: (2000, 3112) and Y shape: (2000,)\n",
      "Testing X shape: (2000, 3112) and Y shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "#load pre-processed data \n",
    "X_train, y_train, dict_vect, vocab_mask = tutorial_utils.get_train_data('../example_data/train_yelp.json')\n",
    "X_test, y_test = tutorial_utils.get_test_group('../example_data/test_yelp.json', vocab_mask, dict_vect)\n",
    "assert X_test.shape[1] == X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq-e usage\n",
    "\n",
    "## Inference\n",
    "Freq-e inference will return (1) a point estimate of the class frequency/proportions and (2) a confidence interval for the point estimate. \n",
    "\n",
    "There are three different ways to obtain estimates: \n",
    "1. Create a `FreqEstimator` object and use the built-in training method. \n",
    "2. You can also train a scikit-learn classifier yourself and pass it in to freq-e. Here the model class is restricted to scikit-learn models that have a .decision_function() method. \n",
    "3. Use the standalone `infer_freq_from_predictions()` method and pass in the predicted probabilities of the positive class of the test set. This may be useful in the cases where you have certain classifier architectures that are not built from sklearn (e.g. an LSTM or CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 (train internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a freq-e object \n",
    "FreqE = freq_e.FreqEstimator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "The FreqEstimator model object can train a discriminative logistic regression classifier for you. It uses grid search over the L1 penalties, evaluating on cross-entropy over 10 cross-validation folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING LOGISTIC REGRESSION MODEL\n",
      "Best model: LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Training mean accuracy= 0.9635\n"
     ]
    }
   ],
   "source": [
    "FreqE.train_cross_val(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference \n",
    "We will get a prevalence point estimate and a 95% confidence interval (the default). One can change the confidence level as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATE\n",
      "{'point': 0.77200000000000002, 'conf_interval': (0.748, 0.79500000000000004), 'conf_level': 0.95}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATE')\n",
    "out = FreqE.infer_freq(X_test, conf_level=0.95)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare this to other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label prevalence:\n",
      "0.769\n"
     ]
    }
   ],
   "source": [
    "# In our example, we know the true class prevalence because we have access to the test labels\n",
    "# This is not the case if you are doing true inference \n",
    "print('True label prevalence:')\n",
    "print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC inference of label prevalence:\n",
      "0.769418519107\n"
     ]
    }
   ],
   "source": [
    "#naive method = PCC (probabilistic classify and count)\n",
    "print('PCC inference of label prevalence:')\n",
    "trained_model = FreqE.trained_model #used the logistic regression model we already trained \n",
    "probs = trained_model.predict_proba(X_test)[:, 1] #get the soft probabilites \n",
    "print(np.mean(probs)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 (pre-trained scikit-learn linear model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also train a scikit-learn classifier yourself and pass it in to freq-e.  This may be useful if you want to use different hyperparameters or different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "trained_model = LinearSVC()\n",
    "trained_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATE\n",
      "{'point': 0.57400000000000007, 'conf_interval': (0.53800000000000003, 0.60899999999999999), 'conf_level': 0.95}\n"
     ]
    }
   ],
   "source": [
    "fe2 = freq_e.FreqEstimator()\n",
    "label_prior = np.mean(y_train) #most often, you want to estimate the label prior from the training labels \n",
    "fe2.set_trained_model(trained_model, label_prior)\n",
    "print('FREQ-E ESTIMATE')\n",
    "out = fe2.infer_freq(X_test)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do a lot worse since we haven't tuned the hyperparameters for the SVC (and we wouldn't recommend SVC over logistic regression for this task)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 (pass in predicted probabilites on the test set)\n",
    "\n",
    "Finally, you can do both the classifier training and prediction yourself.  All you need to do is get the predicted positive class probabilites on the test set (`test_pred_probs`) and pass them into the `infer_freq_from_predictions` standalone method.  We'll do it with sklearn, but you could get them from any model from any software package.  We would recommend using a model with probabilistic predictions (such as, a neural network with logistic output) whose hyperparameters have been tuned with cross-validation or on a development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.75556119e-01   5.67236618e-05   9.99967121e-01   9.80429471e-01\n",
      "   7.78366752e-01]\n"
     ]
    }
   ],
   "source": [
    "# Let's train a LogisticRegression classifier (without hyperparameter tuning) \n",
    "# and get the probabilities for the positive class \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "trained_model2 = LogisticRegression()\n",
    "trained_model2.fit(X_train, y_train)\n",
    "test_pred_probs = trained_model2.predict_proba(X_test)[:, 1] #estimated probabilites for the positive class \n",
    "print(test_pred_probs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATE\n",
      "{'point': 0.78900000000000003, 'conf_interval': (0.76700000000000002, 0.81000000000000005), 'conf_level': 0.95}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATE')\n",
    "label_prior = np.mean(y_train)\n",
    "out = freq_e.infer_freq_from_predictions(test_pred_probs, label_prior)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other test groups \n",
    "Here we examine two other test groups to show some anecdotes of why using our method is important when the training class prevalence does not match the true test class prevalence.  The empirical results in Keith et. al 2018 show this more rigorously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High prevalence test group  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test group has *higher* positive prevalence than the training data.  We expect PCC to give a too-low prediction, while freq-e should be closer to the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing X shape: (415, 3112) and Y shape: (415,)\n"
     ]
    }
   ],
   "source": [
    "X_test2, y_test2 = tutorial_utils.get_test_group('../example_data/high_prev.json', vocab_mask, dict_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label prevalence:\n",
      "0.968674698795\n"
     ]
    }
   ],
   "source": [
    "print('True label prevalence:')\n",
    "print(np.mean(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATE\n",
      "{'point': 0.97299999999999998, 'conf_interval': (0.94400000000000006, 0.99199999999999999), 'conf_level': 0.95}\n"
     ]
    }
   ],
   "source": [
    "# Note: we don't have to re-train our original frequency estimate object! \n",
    "# we can just infer the class proportions on this new test set \n",
    "print('FREQ-E ESTIMATE')\n",
    "out = FreqE.infer_freq(X_test2, conf_level=0.95)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC estimate\n",
      "0.901936558961\n"
     ]
    }
   ],
   "source": [
    "print('PCC estimate')\n",
    "print(np.mean(FreqE.trained_model.predict_proba(X_test2)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low prevalence test group "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test group has *lower* prevalence than the training data.  We expect PCC to be biased upward, but freq-e to be closer to the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing X shape: (825, 3112) and Y shape: (825,)\n"
     ]
    }
   ],
   "source": [
    "X_test3, y_test3 = tutorial_utils.get_test_group('../example_data/low_prev.json', vocab_mask, dict_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label prevalence:\n",
      "0.13696969697\n"
     ]
    }
   ],
   "source": [
    "print('True label prevalence:')\n",
    "print(np.mean(y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATE\n",
      "{'point': 0.045999999999999999, 'conf_interval': (0.028000000000000001, 0.069000000000000006), 'conf_level': 0.95}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATE')\n",
    "out = FreqE.infer_freq(X_test3, conf_level=0.95)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, in this case freq-e's confidence interval fails to cover the true value; as noted in the paper, the coverage rate tends to be too lower than desired, so be careful when using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC estimate\n",
      "0.311480435401\n"
     ]
    }
   ],
   "source": [
    "print('PCC estimate')\n",
    "print(np.mean(FreqE.trained_model.predict_proba(X_test3)[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
