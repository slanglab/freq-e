{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# freq-e tutorial \n",
    "This notebook walks through: \n",
    "How to run freq-e to obtain prevalence estimates on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dependencies \n",
    "import numpy as np \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load freq_e package and tutorial data-preprocessing utils \n",
    "from freq_e import estimate\n",
    "import tutorial_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing \n",
    "freq-e must have data in the following format \n",
    "- `X_train` : numpy.ndarray, shape=(number of training examples, number of features) \n",
    "- `y_train` : numpy.ndarray (binary 0's and 1's), shape=(number of training examples,) \n",
    "- `X_test` : numpy.ndarray, shape=(number of test/inference examples, number of *training* features)\n",
    "\n",
    "Often you will have *multiple* test groups. In this case you should have an `X_test` for each test group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Yelp academic dataset as an example. The text representation will be unigram counts (e.g. \"bag-of-words\"). Here, we have already calcuated the BOW counts and saved them as a .json file. The y-values are negative sentiment (y=0) and positive sentiment (y=1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig vocab 14791, pruned 3112\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(2000, 3112) (2000,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(2000, 3112) (2000,)\n"
     ]
    }
   ],
   "source": [
    "#load pre-processed data \n",
    "X_train, y_train, dict_vect, vocab_mask = tutorial_utils.get_train_data('../example_data/train_yelp.json')\n",
    "X_test, y_test = tutorial_utils.get_test_group('../example_data/test_yelp.json', vocab_mask, dict_vect)\n",
    "assert X_test.shape[1] == X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq-e usage\n",
    "\n",
    "## Inference\n",
    "Freq-e inference will return (1) a point estimate of the class frequency/proportions and (2) a confidence interval for the point estimate. \n",
    "\n",
    "There are three different ways to obtain estimates: \n",
    "1. Create a `FreqEstimate` object and use the built-in training method. \n",
    "2. Use the `infer_freq()` method and pass in a pre-trained scikit-learn linear model (e.g. Logistic_Regression). Here the model class is restricted to scikit-learn models that have a .decision_function() method. \n",
    "3. Use the `infer_freq()` method and pass in the predicted probabilities of the positive class of the test set. \n",
    "\n",
    "Method 3 may be useful in the cases where you have special classifier architectures that are not built from sklearn (e.g. an LSTM or CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 (train internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a freq-e object \n",
    "FreqE = estimate.FreqEstimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "In order to select the best discriminitive classifier, we do a grid search over the L1 penalties for LogReg, evaluating on cross-entropy over 10 cross-validation folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING LOGISTIC REGRESSION MODEL\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=None, solver='liblinear',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Training mean accuracy= 0.9635\n"
     ]
    }
   ],
   "source": [
    "FreqE.train_cross_val(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference \n",
    "We will get a prevalence point estimate and the 95% confidence intervals. One can change the confidence level as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.772, 'conf_interval_95%': (0.748, 0.795)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "out = FreqE.infer_freq_obj(X_test, conf_level=0.95)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare this to other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "0.769\n"
     ]
    }
   ],
   "source": [
    "# In our example, we know the true class proportion because we have access to the test labels\n",
    "# This is not the case if you are doing true inference \n",
    "print('TRUE')\n",
    "print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC\n",
      "0.7694201610577046\n"
     ]
    }
   ],
   "source": [
    "#naive method = PCC (probabilistic classify and count)\n",
    "print('PCC')\n",
    "trained_model = FreqE.trained_model #used the logistic regression model we already trained \n",
    "probs = trained_model.predict_proba(X_test)[:, 1] #get the soft probabilites \n",
    "print(np.mean(probs)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 (pre-trained scikit-learn linear model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we will give an example of passing in a classifier that is not LogisticRegression \n",
    "# We will show that we can also use a LinearSVC (linear support vector classifier)\n",
    "from sklearn.svm import LinearSVC\n",
    "trained_model = LinearSVC()\n",
    "trained_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.5740000000000001, 'conf_interval_95%': (0.538, 0.609)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "label_prior = np.mean(y_train) #most often, you want to estimate the label prior from training, but you can also pass in other values\n",
    "out = estimate.infer_freq(X_test, label_prior, conf_level=0.95, trained_model=trained_model)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do a lot worse since we obviously haven't tuned the hyperparameters for the SVC. However, if a user is using a classifier that has been fine-tuned on the training data (e.g. a LSTM or Transformer) this method should work well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 (pass in predicted probabilites on the test set)\n",
    "Train a classifier, get the predicted positive class probabilites on the test set (`test_pred_probs`) and pass this into the `infer_freq` stand-alone method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.75550754e-01 5.67237177e-05 9.99967122e-01 9.80429407e-01\n",
      " 7.78366952e-01]\n"
     ]
    }
   ],
   "source": [
    "# Let's train a LogisticRegression classifier (without hyperparameter tuning) \n",
    "# and get the probabilities for the positive class \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "trained_model2 = LogisticRegression()\n",
    "trained_model2.fit(X_train, y_train)\n",
    "test_pred_probs = trained_model2.predict_proba(X_test)[:, 1] #estimated probabilites for the positive class \n",
    "print(test_pred_probs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.789, 'conf_interval_95%': (0.767, 0.81)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "label_prior = np.mean(y_train)\n",
    "out = estimate.infer_freq(X_test, label_prior, conf_level=0.95, trained_model=None, test_pred_probs=test_pred_probs)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other test groups \n",
    "Here we examine two other test groups to show some anecdotes (supported by empirical results in Keith et. al 2018) of why using our method is important when the training class prevalence does not match the true test class prevalence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High prevalence test group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(415, 3112) (415,)\n",
      "(415, 3112) (415,)\n"
     ]
    }
   ],
   "source": [
    "X_test2, y_test2 = tutorial_utils.get_test_group('../example_data/high_prev.json', vocab_mask, dict_vect)\n",
    "print(X_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "0.9686746987951808\n"
     ]
    }
   ],
   "source": [
    "print('TRUE')\n",
    "print(np.mean(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.973, 'conf_interval_95%': (0.9440000000000001, 0.992)}\n"
     ]
    }
   ],
   "source": [
    "# Note: we don't have to re-train our frequency estimate object! we can just infer the \n",
    "# class proportions on this new test set \n",
    "print('FREQ-E ESTIMATED')\n",
    "out = FreqE.infer_freq_obj(X_test2, conf_level=0.95)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC\n",
      "0.9019349059317472\n"
     ]
    }
   ],
   "source": [
    "print('PCC')\n",
    "print(np.mean(FreqE.trained_model.predict_proba(X_test2)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low prevalence test group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(825, 3112) (825,)\n",
      "(825, 3112) (825,)\n"
     ]
    }
   ],
   "source": [
    "X_test3, y_test3 = tutorial_utils.get_test_group('../example_data/low_prev.json', vocab_mask, dict_vect)\n",
    "print(X_test3.shape, y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "0.13696969696969696\n"
     ]
    }
   ],
   "source": [
    "print('TRUE')\n",
    "print(np.mean(y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ-E ESTIMATED\n",
      "{'point': 0.046, 'conf_interval_95%': (0.028, 0.069)}\n"
     ]
    }
   ],
   "source": [
    "print('FREQ-E ESTIMATED')\n",
    "out = FreqE.infer_freq_obj(X_test3, conf_level=0.95)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC\n",
      "0.3114774782928134\n"
     ]
    }
   ],
   "source": [
    "print('PCC')\n",
    "print(np.mean(FreqE.trained_model.predict_proba(X_test3)[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
